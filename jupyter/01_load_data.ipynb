{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6641d0cb",
   "metadata": {},
   "source": [
    "# Load data to InfluxDB\n",
    "\n",
    "InfluxDB is a non relational data base specific for time series data sets. It has meany features, one is that can handle SQL like queries.\n",
    "\n",
    "Here are shown the key steps to load the data una array of jsons to a measurement or **table** in InfluxDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2785678f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "from influxdb_client import InfluxDBClient, Point, WritePrecision\n",
    "from influxdb_client.client.write_api import SYNCHRONOUS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4db798e",
   "metadata": {},
   "source": [
    "Now we perform the actual connection to the db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a18bf236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working connection on http://influxdb:8086\n"
     ]
    }
   ],
   "source": [
    "url = \"http://influxdb:8086\"\n",
    "token = \"my-admin-token\"\n",
    "org = \"my-org\"\n",
    "bucket = \"my-bucket\"\n",
    "\n",
    "with InfluxDBClient(url=url, token=token, org=org) as client:\n",
    "    if not client.ping():\n",
    "        raise AttributeError(\"Can't setup connection to InfluxDB\")\n",
    "    else:\n",
    "        print(f'Working connection on {client.url}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73146bc",
   "metadata": {},
   "source": [
    "Now we load the json file and setup the payload structure to be load into this Influxdb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3d27b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "starklink_datafile = 'starlink_historical_data.json'\n",
    "\n",
    "with open(starklink_datafile, 'r') as data_file:\n",
    "    json_data = data_file.read()\n",
    "\n",
    "starklink_data = json.loads(json_data)\n",
    "\n",
    "points = [\n",
    "    Point('sat_pos_' + data['id'])\\\n",
    "    .field('lat', float(data['latitude']))\\\n",
    "    .field('lon', float(data['longitude']))\\\n",
    "    .time(data['spaceTrack']['CREATION_DATE'])\n",
    "    \n",
    "    for data in starklink_data if data['latitude'] and data['longitude'] ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be2c54a",
   "metadata": {},
   "source": [
    "As we can see here, the payload consist on a list of dictionaries, where the key fields on these dictionaries are\n",
    "\n",
    "    1. measurement: this is like the SQL DB where all the data will be allocated inside the DB.\n",
    "    2. time: this is a ISO8601 or similar datetime string\n",
    "    3. fields: points to a dict of the actual pair key-value of data stored\n",
    "  \n",
    "As an example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e005021c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_tags': {},\n",
       " '_fields': {'lat': -28.351511934981414, 'lon': 41.0},\n",
       " '_name': 'sat_pos_5eed7714096e5900069856a2',\n",
       " '_time': '2021-01-26T02:30:00',\n",
       " '_write_precision': 'ns'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(points[100].__dict__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f424fe41",
   "metadata": {},
   "source": [
    "Now with the payload constructed, we can do the actual write to the DB and then query for these measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "699e12d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with InfluxDBClient(url=url, token=token, org=org) as client:\n",
    "    write_api = client.write_api(write_options=SYNCHRONOUS)\n",
    "    write_api.write(bucket=bucket, record=points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53581ab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#datatype, string, long, dateTime:RFC3339, dateTime:RFC3339, dateTime:RFC3339, double, string, string\n",
      "#group, false, false, true, true, false, false, true, true\n",
      "#default, _result, , , , , , , \n",
      ", result, table, _start, _stop, _time, _value, _field, _measurement\n",
      ", , 0, 2019-01-20T09:35:18.8427593Z, 2022-01-20T03:35:18.8427593Z, 2021-01-21T06:26:10Z, 155, lon, sat_pos_5eed7714096e5900069856a2\n",
      ", , 0, 2019-01-20T09:35:18.8427593Z, 2022-01-20T03:35:18.8427593Z, 2021-01-26T02:30:00Z, 41, lon, sat_pos_5eed7714096e5900069856a2\n",
      ", , 0, 2019-01-20T09:35:18.8427593Z, 2022-01-20T03:35:18.8427593Z, 2021-01-26T06:26:10Z, 5, lon, sat_pos_5eed7714096e5900069856a2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with InfluxDBClient(url=url, token=token, org=org) as client:\n",
    "    query_api = client.query_api()\n",
    "    csv_result = query_api.query_csv(\n",
    "        \"\"\"\n",
    "        from(bucket: \"my-bucket\")\n",
    "          |> range(start: -3y)\n",
    "          |> filter(fn: (r) => r[\"_measurement\"] == \"sat_pos_5eed7714096e5900069856a2\")\n",
    "          |> filter(fn: (r) => r[\"_field\"] == \"lon\")\n",
    "        \"\"\")\n",
    "    \n",
    "for row in csv_result:\n",
    "    print(', '.join(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0770a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
